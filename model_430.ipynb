{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_430.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zJmsrHWZnn9"
      },
      "source": [
        "# 0) Импорт всех нужных библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvkkLtayRybJ"
      },
      "source": [
        "!rm -rf datas"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blh_Mh2iLnxQ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D , UpSampling2D ,Conv2DTranspose\n",
        "from imutils.object_detection import non_max_suppression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXU4n7uNas6d"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3oslv2UJj3K"
      },
      "source": [
        "# 1) Подготовка датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_4mvkgIfOCs",
        "outputId": "231d6a2f-63f2-414d-e8b1-c48cc8f76701"
      },
      "source": [
        "! rm datas150k.rar\n",
        "! wget https://www.dropbox.com/s/542b4om2x4jw4dr/datas150k.rar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'datas150k.rar': No such file or directory\n",
            "--2021-04-20 19:53:50--  https://www.dropbox.com/s/542b4om2x4jw4dr/datas150k.rar\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:601a:18::a27d:712\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/542b4om2x4jw4dr/datas150k.rar [following]\n",
            "--2021-04-20 19:53:50--  https://www.dropbox.com/s/raw/542b4om2x4jw4dr/datas150k.rar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc8e992f2f1440fc56e2753ee2e7.dl.dropboxusercontent.com/cd/0/inline/BM_3KGquXtLOm_FlirDTfrIfcf-2kxLQDi-zJisCL9mFqGHZEvEf2mShf5FiuHjawvvzrV9tO570pMFz5XrkNkyiEFsnbnoz3HH8ThFgSXdebxQtzrwzak24XnMNCih2lU8P9E9Tfdk5PiEeM5MTC6_Z/file# [following]\n",
            "--2021-04-20 19:53:51--  https://uc8e992f2f1440fc56e2753ee2e7.dl.dropboxusercontent.com/cd/0/inline/BM_3KGquXtLOm_FlirDTfrIfcf-2kxLQDi-zJisCL9mFqGHZEvEf2mShf5FiuHjawvvzrV9tO570pMFz5XrkNkyiEFsnbnoz3HH8ThFgSXdebxQtzrwzak24XnMNCih2lU8P9E9Tfdk5PiEeM5MTC6_Z/file\n",
            "Resolving uc8e992f2f1440fc56e2753ee2e7.dl.dropboxusercontent.com (uc8e992f2f1440fc56e2753ee2e7.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:601a:15::a27d:70f\n",
            "Connecting to uc8e992f2f1440fc56e2753ee2e7.dl.dropboxusercontent.com (uc8e992f2f1440fc56e2753ee2e7.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BM8j9q2mrh0MJFNFqSqg6tAxHK_xxhJrvvtyN1nBJ1XBZi3piiujj37LaJ7GXpQiNCckCBzkMWfGumlTz1u8pJzkg6pfWry3b6ecIoQW67z4thvjuju-ZPg6XmLZ5u38eZkYD0Ijo6JFCmUaVj1ZQRUd-_mDY-6Jub1FRAx4cy-GD8h-byATErVBuj89K9l53RlFrZeCIqqxLzLZT1o-2SQ64HwuBoMhO5Hz0iAl2zwZ0GOmddV4HcNYV6EtM3s3OcGNX4RbGu4YQwPPN5OKkyD_FnnMlgGSZWUdIXY6bG5uHilf9h173_6c_BZCVzhs8UCSgC-9wANREpXK_osoeTNM0xMBohG8aG6AJSRjcwy7jaQ0dgRdWv1UjdHxwux3mLQ/file [following]\n",
            "--2021-04-20 19:53:51--  https://uc8e992f2f1440fc56e2753ee2e7.dl.dropboxusercontent.com/cd/0/inline2/BM8j9q2mrh0MJFNFqSqg6tAxHK_xxhJrvvtyN1nBJ1XBZi3piiujj37LaJ7GXpQiNCckCBzkMWfGumlTz1u8pJzkg6pfWry3b6ecIoQW67z4thvjuju-ZPg6XmLZ5u38eZkYD0Ijo6JFCmUaVj1ZQRUd-_mDY-6Jub1FRAx4cy-GD8h-byATErVBuj89K9l53RlFrZeCIqqxLzLZT1o-2SQ64HwuBoMhO5Hz0iAl2zwZ0GOmddV4HcNYV6EtM3s3OcGNX4RbGu4YQwPPN5OKkyD_FnnMlgGSZWUdIXY6bG5uHilf9h173_6c_BZCVzhs8UCSgC-9wANREpXK_osoeTNM0xMBohG8aG6AJSRjcwy7jaQ0dgRdWv1UjdHxwux3mLQ/file\n",
            "Reusing existing connection to uc8e992f2f1440fc56e2753ee2e7.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 921399537 (879M) [application/rar]\n",
            "Saving to: ‘datas150k.rar’\n",
            "\n",
            "datas150k.rar       100%[===================>] 878.71M   110MB/s    in 8.4s    \n",
            "\n",
            "2021-04-20 19:54:00 (105 MB/s) - ‘datas150k.rar’ saved [921399537/921399537]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaOHbTIvIGPQ"
      },
      "source": [
        "get_ipython().system_raw(\"unrar x datas150k.rar\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEPF3TfaI-6s"
      },
      "source": [
        "DATA_PATH = 'datas/'\n",
        "IMG_SIZE = [64, 128, 3]\n",
        "batch_size = 128"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8z8MH9XSLOT",
        "outputId": "e2979fec-83db-415b-f658-19058f17ffc1"
      },
      "source": [
        "import os\n",
        "classes = [f for f in os.listdir(DATA_PATH)]\n",
        "classes.sort()\n",
        "NUM_OF_CLASSES = len(classes)\n",
        "classes"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['antqua',\n",
              " 'arial',\n",
              " 'bahnschrift',\n",
              " 'book antiqua',\n",
              " 'bookman old style',\n",
              " 'calibri',\n",
              " 'cambria',\n",
              " 'candara',\n",
              " 'century',\n",
              " 'century schoolbook',\n",
              " 'comic sans',\n",
              " 'consolas',\n",
              " 'constantia',\n",
              " 'corbel',\n",
              " 'courier new',\n",
              " 'gabriola',\n",
              " 'garamond',\n",
              " 'georgia',\n",
              " 'gothic',\n",
              " 'haettenschweiler',\n",
              " 'impact',\n",
              " 'lucida console',\n",
              " 'lucida sans unicode',\n",
              " 'microsoft sans serif',\n",
              " 'mistral',\n",
              " 'monotype corsiva',\n",
              " 'ms rederence sans serif',\n",
              " 'palatino linotype',\n",
              " 'segoe print',\n",
              " 'segoe script',\n",
              " 'segoe ui',\n",
              " 'sitka',\n",
              " 'sylfaen',\n",
              " 'tahoma',\n",
              " 'times new roman',\n",
              " 'trebuchet ms',\n",
              " 'verdana']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohQUEINqPO29"
      },
      "source": [
        "def normalize_img(image, label):\n",
        "  return tf.cast(image, tf.float32) / 255.0, label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exgd7e3XIheR",
        "outputId": "46d5ff36-f16a-4b8e-b822-d5721b7e8727"
      },
      "source": [
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    DATA_PATH,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=classes,\n",
        "    batch_size=batch_size,\n",
        "    image_size=tuple(IMG_SIZE[:-1]),\n",
        "    validation_split=0.1,\n",
        "    seed=1488,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    DATA_PATH,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=classes,\n",
        "    batch_size=batch_size,\n",
        "    image_size=tuple(IMG_SIZE[:-1]),\n",
        "    validation_split=0.1,\n",
        "    seed=1488,\n",
        "    subset='validation'\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 150000 files belonging to 37 classes.\n",
            "Using 135000 files for training.\n",
            "Found 150000 files belonging to 37 classes.\n",
            "Using 15000 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB6R7KoVPdSF"
      },
      "source": [
        "ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_validation = ds_validation.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N9Sd4zwapZs"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSbQBpIzJ6Ym"
      },
      "source": [
        "# 2) Создание и обучение модели для классификации шрифтов\n",
        "\n",
        "#### Также здесь я дополнительно обучил модель ResNet50, чтобы сравнить с ней точность работы моей модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAR4VXStK77m"
      },
      "source": [
        "#### Моя модель:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccIoXlSf6eUi"
      },
      "source": [
        "##### Создание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQN5EjB-zKzN"
      },
      "source": [
        "def get_model(input_shape_, num_classes):\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "       layers.experimental.preprocessing.Resizing(64, 128),\n",
        "\n",
        "       layers.Conv2D(8, 3, padding='same', input_shape=input_shape_),\n",
        "       layers.BatchNormalization(),\n",
        "       layers.MaxPool2D(strides=(2,2)),\n",
        "       layers.ReLU(),\n",
        "\n",
        "       layers.Conv2D(16, 3, padding='same'),\n",
        "       layers.BatchNormalization(),\n",
        "       layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "       layers.ReLU(),\n",
        "\n",
        "       layers.Conv2D(32, 3, padding='same'),\n",
        "       layers.BatchNormalization(),\n",
        "       layers.MaxPool2D(strides=(2,2)),\n",
        "       layers.ReLU(),\n",
        "\n",
        "       layers.Conv2D(16, 3, padding='same'),\n",
        "       layers.BatchNormalization(),\n",
        "       layers.MaxPool2D(strides=(2,2)),\n",
        "       layers.ReLU(),\n",
        "\n",
        "      #  layers.Conv2D(64, 3, padding='same'),\n",
        "      #  layers.BatchNormalization(),\n",
        "      #  layers.MaxPool2D(strides=(2,2)),\n",
        "      #  layers.ReLU(),\n",
        "       \n",
        "      #  layers.Conv2D(128, 3, padding='same', input_shape=[16, 32, 64], data_format='channels_last'),\n",
        "      #  layers.BatchNormalization(),\n",
        "      #  layers.MaxPool2D(strides=(2,2)),\n",
        "      #  layers.ReLU(),\n",
        "\n",
        "      #  layers.Conv2D(128, 3, padding='same', input_shape=[8, 16, 128], data_format='channels_last'),\n",
        "      #  layers.BatchNormalization(),\n",
        "      #  layers.MaxPool2D(strides=(2,2)),\n",
        "      #  layers.ReLU(),\n",
        "\n",
        "       layers.Flatten(),\n",
        "       layers.Dense(256, activation='relu',\n",
        "                    ),\n",
        "       layers.Dense(256, activation='relu',\n",
        "                    ),\n",
        "       layers.Dropout(0.4),\n",
        "       layers.Dense(32, activation='relu',\n",
        "                    ),\n",
        "       layers.Dense(40, activation='relu',\n",
        "                    ),\n",
        "       layers.Dropout(0.15),\n",
        "       layers.Dense(num_classes, activation='softmax', \n",
        "                  # kernel_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.01)\n",
        "                  )\n",
        "      ]\n",
        "  )\n",
        "  model.build([None] + input_shape_)\n",
        "  return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdqEJfx2Kzn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b472d37-7592-463f-dbe3-bfc28c32619a"
      },
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    1e-3,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9,\n",
        "    staircase=False)\n",
        "model = get_model(IMG_SIZE, NUM_OF_CLASSES)\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "              loss=keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[keras.metrics.TopKCategoricalAccuracy(k=3)],)\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resizing (Resizing)          (None, 64, 128, 3)        0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 64, 128, 8)        224       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 64, 128, 8)        32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 64, 8)         0         \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 32, 64, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 64, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 64, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 16, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 32, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 16, 32)         0         \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 8, 16, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 16, 16)         4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 16, 16)         64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 4, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 40)                1320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 37)                1517      \n",
            "=================================================================\n",
            "Total params: 219,125\n",
            "Trainable params: 218,981\n",
            "Non-trainable params: 144\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9z7hKvV6l28"
      },
      "source": [
        "##### Обучение и тест"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYwm_i7T1aZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab5ef215-4e12-4402-e3f5-e4a8c5caf61d"
      },
      "source": [
        "model.fit(ds_train, batch_size=batch_size, epochs=8, verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "1055/1055 [==============================] - 118s 110ms/step - loss: 2.1835 - top_k_categorical_accuracy: 0.5714\n",
            "Epoch 2/8\n",
            "1055/1055 [==============================] - 123s 116ms/step - loss: 1.1689 - top_k_categorical_accuracy: 0.8517\n",
            "Epoch 3/8\n",
            "1055/1055 [==============================] - 124s 117ms/step - loss: 0.9244 - top_k_categorical_accuracy: 0.8971\n",
            "Epoch 4/8\n",
            "1055/1055 [==============================] - 124s 117ms/step - loss: 0.7864 - top_k_categorical_accuracy: 0.9212\n",
            "Epoch 5/8\n",
            "1055/1055 [==============================] - 126s 118ms/step - loss: 0.7053 - top_k_categorical_accuracy: 0.9335\n",
            "Epoch 6/8\n",
            "1055/1055 [==============================] - 132s 125ms/step - loss: 0.6473 - top_k_categorical_accuracy: 0.9416\n",
            "Epoch 7/8\n",
            "1055/1055 [==============================] - 131s 123ms/step - loss: 0.5974 - top_k_categorical_accuracy: 0.9481\n",
            "Epoch 8/8\n",
            "1055/1055 [==============================] - 130s 123ms/step - loss: 0.5607 - top_k_categorical_accuracy: 0.9532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f363582aa10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGaax5FUQ1Zx",
        "outputId": "bf4dc904-9578-4b18-b1cf-ba1eea39fa41"
      },
      "source": [
        "loss, acc = model.evaluate(ds_validation)\n",
        "acc"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118/118 [==============================] - 14s 110ms/step - loss: 0.5027 - top_k_categorical_accuracy: 0.9564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9563999772071838"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUlf67s_am3-"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZjGR_zrLClY"
      },
      "source": [
        "#### ResNet50V2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRniUQG7Oxw1"
      },
      "source": [
        "m = keras.applications.ResNet50V2(weights=None, input_shape=IMG_SIZE, classes=NUM_OF_CLASSES)\n",
        "m.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[keras.metrics.TopKCategoricalAccuracy(k=3)],)\n",
        "m.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65zvmBj9PSU2",
        "outputId": "f585d03f-a326-42db-9e0f-8dff046f2a78"
      },
      "source": [
        "m.fit(ds_train, batch_size=batch_size, epochs=8, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1055/1055 [==============================] - 255s 241ms/step - loss: 0.1906 - top_k_categorical_accuracy: 0.9918\n",
            "Epoch 2/2\n",
            "1055/1055 [==============================] - 259s 245ms/step - loss: 0.1660 - top_k_categorical_accuracy: 0.9938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffafc678c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUibVvUNlOL0",
        "outputId": "aef319e0-9b10-4a35-f4fa-54da31b2052d"
      },
      "source": [
        "loss, acc = m.evaluate(ds_validation)\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118/118 [==============================] - 11s 90ms/step - loss: 0.4359 - top_k_categorical_accuracy: 0.9796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9796000123023987"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKy8vvDFZ7EQ"
      },
      "source": [
        "Из сравнения видно, что наша модель несильно уступает модели ResNet50V2 в качестве, но при этом она значительно меньше по объему(ResNet50V2 - 90мб, наша модель - 800кб)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwryOk-DL9tu"
      },
      "source": [
        "# 3) Код для постобработки выхода модели для детекции\n",
        "### Будет использоваться в проекте, но не в этом ноутбуке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13AxNd4rQvaF"
      },
      "source": [
        "Код в следующей ячейке взят из [этого ноутбука](https://colab.research.google.com/github/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/EAST_TFLite.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE6qMhOfQtye"
      },
      "source": [
        "def post_process(score, geo, ratioW, ratioH):\n",
        "    (numRows, numCols) = score.shape[2:4]\n",
        "    rects = []\n",
        "    confidences = []\n",
        "\n",
        "    for y in range(0, numRows):\n",
        "        scoresData = score[0, 0, y]\n",
        "        xData0 = geo[0, 0, y]\n",
        "        xData1 = geo[0, 1, y]\n",
        "        xData2 = geo[0, 2, y]\n",
        "        xData3 = geo[0, 3, y]\n",
        "        anglesData = geo[0, 4, y]\n",
        "\n",
        "        for x in range(0, numCols):\n",
        "\n",
        "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
        "\n",
        "            angle = anglesData[x]\n",
        "            cos = np.cos(angle)\n",
        "            sin = np.sin(angle)\n",
        "\n",
        "            h = xData0[x] + xData2[x]\n",
        "            w = xData1[x] + xData3[x]\n",
        "\n",
        "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
        "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
        "            startX = int(endX - w)\n",
        "            startY = int(endY - h)\n",
        "\n",
        "            rects.append((startX, startY, endX, endY))\n",
        "            confidences.append(scoresData[x])\n",
        "\n",
        "    selected_indices = tf.image.non_max_suppression(rects, confidences, max_output_size=5, iou_threshold=0.3, score_threshold=0.5)\n",
        "    boxes = np.array(tf.gather(rects, selected_indices))\n",
        "\n",
        "    boxes2 = []\n",
        "    for (startX, startY, endX, endY) in boxes:\n",
        "        startX = min(max(int(startX * ratioW), 0), W)\n",
        "        startY = min(max(int(startY * ratioH), 0), H)\n",
        "        endX = min(max(int(endX * ratioW), 0), W)\n",
        "        endY = min(max(int(endY * ratioH), 0), H)\n",
        "        boxes2.append((startX, startY, endX, endY))\n",
        "    return np.array(boxes2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyKTkGkxaxDz"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-M8YlpZLktu"
      },
      "source": [
        "# 4) Сохранение модели в формате .tflite\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP_OHtvDN9Wz"
      },
      "source": [
        "model_index = 0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w976tKyVXUbp",
        "outputId": "fcb1ca9d-9ade-4061-9614-282bb18a3623"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model{}({}%).tflite'.format(model_index, int(acc*100)), 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "  model_index += 1"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp_ryif3_9/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}